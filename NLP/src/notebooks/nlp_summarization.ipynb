{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5339dccc-477a-47cd-9189-d010c52f5e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcsal\\miniconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import logging as hf_logging, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4615cb0-0681-4d9f-ac41-24f5aa4be981",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.ERROR)\n",
    "hf_logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fabc392-952a-4e05-b388-4e665638496e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eaa1dc0-2015-448d-aed1-51cdb37e80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-pegasus\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"nsi319/legal-pegasus\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656e6618-701a-4bd4-a23e-08cf1f7a14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, length):\n",
    "    # Preprocess and tokenize the text efficiently\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", truncation=True, max_length=length).to(device)\n",
    "    # Generate summaries with optimized parameters\n",
    "    summary_ids = model.generate(inputs, max_length=length, min_length=2, length_penalty=2.5, num_beams=5, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62a1889-11c5-4b36-b20a-1eb770ac694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newText = \"\"\"\n",
    "Your Content. You may provide input to the Services (“Input”), and receive output from the Services based on the Input (“Output”). Input and Output are collectively “Content.” You are responsible for Content, including ensuring that it does not violate any applicable law or these Terms. You represent and warrant that you have all rights, licenses, and permissions needed to provide Input to our Services.\n",
    "\n",
    "Ownership of Content. As between you and OpenAI, and to the extent permitted by applicable law, you (a) retain your ownership rights in Input and (b) own the Output. We hereby assign to you all our right, title, and interest, if any, in and to Output. \n",
    "\n",
    "Similarity of Content. Due to the nature of our Services and artificial intelligence generally, output may not be unique and other users may receive similar output from our Services. Our assignment above does not extend to other users’ output or any Third Party Output. \n",
    "\n",
    "Our Use of Content. We may use Content to provide, maintain, develop, and improve our Services, comply with applicable law, enforce our terms and policies, and keep our Services safe. \n",
    "\n",
    "Opt Out. If you do not want us to use your Content to train our models, you can opt out by following the instructions in this Help Center article. Please note that in some cases this may limit the ability of our Services to better address your specific use case.\n",
    "\n",
    "Accuracy. Artificial intelligence and machine learning are rapidly evolving fields of study. We are constantly working to improve our Services to make them more accurate, reliable, safe, and beneficial. Given the probabilistic nature of machine learning, use of our Services may, in some situations, result in Output that does not accurately reflect real people, places, or facts. \n",
    "\n",
    "When you use our Services you understand and agree:\n",
    "\n",
    "Output may not always be accurate. You should not rely on Output from our Services as a sole source of truth or factual information, or as a substitute for professional advice.\n",
    "You must evaluate Output for accuracy and appropriateness for your use case, including using human review as appropriate, before using or sharing Output from the Services.\n",
    "You must not use any Output relating to a person for any purpose that could have a legal or material impact on that person, such as making credit, educational, employment, housing, insurance, legal, medical, or other important decisions about them. \n",
    "Our Services may provide incomplete, incorrect, or offensive Output that does not represent OpenAI’s views. If Output references any third party products or services, it doesn’t mean the third party endorses or is affiliated with OpenAI.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18604c2-e6e6-4793-8188-5123cec5103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_text = \" \".join(newText.strip().split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c53512-9d83-47a8-a452-4d23ba2ec476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may provide input to OpenAI's services, and receive output from the services based on the input. You represent and warrant that you have all rights, licenses, and permissions needed to provide Input to our Services. You are responsible for Content, including ensuring that it does not violate any applicable law or these Terms.\n"
     ]
    }
   ],
   "source": [
    "# Summarize the preprocessed text\n",
    "summary = summarize_text(preprocessed_text, 100)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006bf78-8ca4-4507-8a05-0d71c8628e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
